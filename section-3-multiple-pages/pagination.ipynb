{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page1\n",
      "soup object created\n",
      "links created\n",
      "scraping starts ...\n",
      "<!doctype html>\n",
      "<html lang=\"en\" dir=\"ltr\">\n",
      "<head>\n",
      "\t<!-- Global site tag (gtag.js) - Google Analytics -->\n",
      "<script async src=\"https://www.googletagmanager.com/gtag/js?id=UA-120598793-1\"></script>\n",
      "<script>\n",
      "  window.dataLayer = window.dataLayer || [];\n",
      "  function gtag(){dataLayer.push(arguments);}\n",
      "  gtag('js', new Date());\n",
      "\n",
      "  gtag('config', 'UA-120598793-1');\n",
      "</script>\n",
      "\n",
      "\t<meta charset=\"utf-8\">\n",
      "\t<title>Not found page  | Subs like Script</title>\n",
      "\t<meta name=\"description\" content=\"Page is not found \">\n",
      "\t<meta name=\"keywords\" content=\"subtitles, scripts, movie, film, video, not found \">\n",
      "\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
      "\t<meta name=\"robots\" content=\"index, follow\">\n",
      "\t<link rel=\"shortcut icon\" href=\"/favicon.ico\">\n",
      "\t<link media=\"all\" type=\"text/css\" rel=\"stylesheet\" href=\"/styles/main.css\">\n",
      "\t\n",
      "\t\t\t</head>\n",
      "<body>\n",
      "\t<div class=\"page-wrapper\"> \n",
      "\t\t<header>\n",
      "\t\t\t<div id=\"logo\">\n",
      "\t\t\t\t<a href=\"/\" title=\"Subs like Script - all Movies and TV Shows Transcripts\">\n",
      "\t\t\t\t\t<span>SUBSLIKESCRIPT</span>\n",
      "\t\t\t\t</a>\n",
      "\t\t\t</div>\n",
      "\t\t\t<nav>\n",
      "\t\t\t\t<a target=\"_self\" href=\"/movies\" title=\"All movies transcripts\">Movies</a>\n",
      "\t\t\t\t<a target=\"_self\" href=\"/series\" title=\"All Tv Shows transcripts\">TV Shows</a>\n",
      "\t\t\t</nav>\n",
      "\t    </header>\n",
      "\t    <div class=\"main-wrapper\">\n",
      "\t        <main class=\"mainpage\">\n",
      "\t        \t\n",
      "<article class=\"main-article\">\n",
      "\t<h1>The page is not found</h1>\n",
      "\t<p>Go to <a href=\"/\">home page</a></p>\n",
      "</article>\n",
      "\n",
      "\t        </main>\n",
      "\t        <div class=\"left-side\"></div>\n",
      "\t        <div class=\"right-side\"></div>\n",
      "    \t</div>\n",
      "    \t<!--main-wrapper div ending-->\n",
      "        <footer>\n",
      "           <span class=\"contactus\">Have any questions? Contact us: subslikescript(doggysign)gmail.com | <a href=\"/dmca\">DMCA</a></span>\n",
      "        </footer>\n",
      "    </div>\n",
      "    <!-- wrapper ends -->\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<script>(function(){var js = \"window['__CF$cv$params']={r:'7bffb34b38a84f64',m:'oyfdHYMKoDb.mGKIrqqqnqRUUyrEoUemQE7oWQkamAM-1682856823-0-AQQPb9QPDo5vhuG/hv+wMr+Ia6/TpG2rsZvIxadmexio',u:'/cdn-cgi/challenge-platform/h/g'};_cpo=document.createElement('script');_cpo.nonce='',_cpo.src='/cdn-cgi/challenge-platform/scripts/invisible.js',document.getElementsByTagName('head')[0].appendChild(_cpo);\";var _0xh = document.createElement('iframe');_0xh.height = 1;_0xh.width = 1;_0xh.style.position = 'absolute';_0xh.style.top = 0;_0xh.style.left = 0;_0xh.style.border = 'none';_0xh.style.visibility = 'hidden';document.body.appendChild(_0xh);function handler() {var _0xi = _0xh.contentDocument || _0xh.contentWindow.document;if (_0xi) {var _0xj = _0xi.createElement('script');_0xj.nonce = '';_0xj.innerHTML = js;_0xi.getElementsByTagName('head')[0].appendChild(_0xj);}}if (document.readyState !== 'loading') {handler();} else if (window.addEventListener) {document.addEventListener('DOMContentLoaded', handler);} else {var prev = document.onreadystatechange || function () {};document.onreadystatechange = function (e) {prev(e);if (document.readyState !== 'loading') {document.onreadystatechange = prev;handler();}};}})();</script></body>\n",
      "</html>\n",
      "Error at The page is not found\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "root = \"https://subslikescript.com\"\n",
    "website = f'{root}/movies_letter-A'\n",
    "content = requests.get(website).text\n",
    "soup = BeautifulSoup(content, 'lxml')\n",
    "path = '/Users/hajirufai/udemy-webscraping/section-3-multiple-pages/movies_scraped'\n",
    "\n",
    "\"\"\"My convention 'box' is the name of element which has our interest elements to \n",
    "be scraped\"\"\"\n",
    "# pagination\n",
    "pagination_box = soup.find('nav', class_='pagination_pages')  \n",
    "pages = pagination_box.find_all('li', class_='page-item')\n",
    "last_page = pages[-2]  # convention of last page element OR get your own custom\n",
    "last_page_number = int(last_page.text)\n",
    "\n",
    "# print('len(pages)', len(pages))  # => 13\n",
    "try:\n",
    "\n",
    "    for page in range(1, (last_page_number)+1): # 132 + 1\n",
    "        print(f\"Page{page}\")\n",
    "        page_site = f'{website}?page={page}'\n",
    "        page_content = requests.get(website).text\n",
    "        soup = BeautifulSoup(page_content, 'lxml')\n",
    "        print(\"soup object created\")\n",
    "\n",
    "        # scraping multiple links withing the same page_content\n",
    "        ul_box = soup.find('ul', class_=\"scripts-list\")\n",
    "        # creating links\n",
    "        links = []\n",
    "        for link in ul_box.find_all('a', href=True):  # NOTE: This is how to get links\n",
    "            links.append(link)\n",
    "        \n",
    "        print(\"links created\")\n",
    "\n",
    "        os.makedirs(f\"{path}/{page}\", exist_ok=True) # the latter arguement is to handle e\n",
    "        # print(\"directory created\")\n",
    "        file_path = f'{path}/{page}'\n",
    "        print(\"scraping starts ...\")\n",
    "        for link in links:\n",
    "            # for each link in Links get its content and scrape\n",
    "            content = requests.get(f'{root}/{link}').text\n",
    "            print(content)\n",
    "            soup = BeautifulSoup(content, 'lxml')\n",
    "            article_box = soup.find('div', class_='main-article')\n",
    "            \"\"\"article box element contains movie title, plot and transcript\"\"\"\n",
    "            title = article_box.find('h1').get_text()\n",
    "            plot = article_box.find('p', class_=    'plot').get_text()\n",
    "            transcript = article_box.find('div', class_=\"full-script\").get_text(strip=True, separator=' ')\n",
    "\n",
    "            title = re.sub('/', '-')\n",
    "            with open(fr'{file_path}/{title}.txt', 'a') as file:\n",
    "                file.write(f'{title}\\n')\n",
    "                file.write(f'PLOT:\\n{plot}\\n')\n",
    "                file.write(f'TRANSCRIPTt:\\n{transcript}\\n')\n",
    "        print(\"Done\")\n",
    "except:\n",
    "    print(f\"Error at {title}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
